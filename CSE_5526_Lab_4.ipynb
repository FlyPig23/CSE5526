{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE 5526 Lab 4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMO6XlqkRZOzCdKwp5/PGux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyPig23/CSE5526/blob/main/CSE_5526_Lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline System"
      ],
      "metadata": {
        "id": "vkOxiJA00AGl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo8JwwS91WT8"
      },
      "outputs": [],
      "source": [
        "# Import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "\n",
        "# Import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following library call downloads the training set and puts it into data/FashionMNIST, and prepares the dataset to be passed into a PyTorch as a tensor."
      ],
      "metadata": {
        "id": "1-OvNyDu-RYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use standard FashionMNIST dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = False,\n",
        "    download = False,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "RKBSOC9S2gd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a network that is a Convolutional Neural Network."
      ],
      "metadata": {
        "id": "fExWzdly-q7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 5, kernel_size = 5)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 5, out_channels = 10, kernel_size = 5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 4 * 4 * 10, out_features = 100)\n",
        "    self.fc2 = nn.Linear(in_features = 100, out_features = 50)\n",
        "\n",
        "    self.out = nn.Linear(in_features = 50, out_features = 10)\n",
        "\n",
        "  # Define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # conv2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # fc1\n",
        "    # Use PyTorch's tensor operation t.reshape to flatten the tensor so it can \n",
        "    # be passed to the dense layer afterward\n",
        "    t = t.reshape(-1, 4 * 4 * 10)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # Don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "metadata": {
        "id": "jD_ho39u-qKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auxiliary function that reports the accuracy on a dataset."
      ],
      "metadata": {
        "id": "bwTSoQOdGKkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, dataloader):\n",
        "  count = 0\n",
        "  correct = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds = network(images)\n",
        "      batch_correct = preds.argmax(dim = 1).eq(labels).sum().item()\n",
        "      batch_count = len(batch[0])\n",
        "      count += batch_count\n",
        "      correct += batch_correct\n",
        "  model.train()\n",
        "  return correct/count"
      ],
      "metadata": {
        "id": "Q-qMJ5GiF-NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for ten epochs, report the training set accuracy after each epoch."
      ],
      "metadata": {
        "id": "BBTK9Sh1GbAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 1000\n",
        "shuffle = True\n",
        "epochs = 10\n",
        "\n",
        "network = Network()\n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "optimizer = optim.Adam(network.parameters(), lr = learning_rate)\n",
        "\n",
        "# Set the network to training mode\n",
        "network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in loader:\n",
        "    images = batch[0]\n",
        "    labels = batch[1]\n",
        "    preds = network(images)\n",
        "    loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch, get_accuracy(network, loader)))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch, get_accuracy(network, test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TFsrAUFGW60",
        "outputId": "d020d0c4-5d9a-4886-faa6-1f6bb6916827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train set accuracy 0.6333333333333333\n",
            "Epoch 1: train set accuracy 0.7264166666666667\n",
            "Epoch 2: train set accuracy 0.7545\n",
            "Epoch 3: train set accuracy 0.7753166666666667\n",
            "Epoch 4: train set accuracy 0.7900166666666667\n",
            "Epoch 5: train set accuracy 0.8000166666666667\n",
            "Epoch 6: train set accuracy 0.8069166666666666\n",
            "Epoch 7: train set accuracy 0.8157833333333333\n",
            "Epoch 8: train set accuracy 0.8230166666666666\n",
            "Epoch 9: train set accuracy 0.83105\n",
            "Epoch 9: test set accuracy 0.8241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison System"
      ],
      "metadata": {
        "id": "DN5CZuRX0KRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Feature Maps (20 feature maps for layer 1, 40 feature maps for layer 2)"
      ],
      "metadata": {
        "id": "K98b9pCGKoqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comparison1_get_accuracy(model, dataloader):\n",
        "  count = 0\n",
        "  correct = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds = comparison1_network(images)\n",
        "      batch_correct = preds.argmax(dim = 1).eq(labels).sum().item()\n",
        "      batch_count = len(batch[0])\n",
        "      count += batch_count\n",
        "      correct += batch_correct\n",
        "  model.train()\n",
        "  return correct/count"
      ],
      "metadata": {
        "id": "LfegJTRzpMqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Comparison1_Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 20, kernel_size = 5)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 20, out_channels = 40, kernel_size = 5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 4 * 4 * 40, out_features = 100)\n",
        "    self.fc2 = nn.Linear(in_features = 100, out_features = 50)\n",
        "\n",
        "    self.out = nn.Linear(in_features = 50, out_features = 10)\n",
        "\n",
        "  # Define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # conv2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # fc1\n",
        "    # Use PyTorch's tensor operation t.reshape to flatten the tensor so it can \n",
        "    # be passed to the dense layer afterward\n",
        "    t = t.reshape(-1, 4 * 4 * 40)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # Don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "metadata": {
        "id": "xDzL2feDpMqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 1000\n",
        "shuffle = True\n",
        "epochs = 10\n",
        "\n",
        "comparison1_network = Comparison1_Network()\n",
        "comparison1_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "comparison1_optimizer = optim.Adam(comparison1_network.parameters(), lr = learning_rate)\n",
        "\n",
        "# Set the network to training mode\n",
        "comparison1_network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in comparison1_loader:\n",
        "    comparison1_images = batch[0]\n",
        "    comparison1_labels = batch[1]\n",
        "    comparison1_preds = comparison1_network(comparison1_images)\n",
        "    comparison1_loss = F.cross_entropy(comparison1_preds, comparison1_labels)\n",
        "\n",
        "    comparison1_optimizer.zero_grad()\n",
        "    comparison1_loss.backward()\n",
        "    comparison1_optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch, comparison1_get_accuracy(comparison1_network, comparison1_loader)))\n",
        "\n",
        "comparison1_test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch, comparison1_get_accuracy(comparison1_network, comparison1_test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d6594e-a21d-4251-a3e0-d9435e91f333",
        "id": "IeAtfll8pMqk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train set accuracy 0.6963333333333334\n",
            "Epoch 1: train set accuracy 0.7555\n",
            "Epoch 2: train set accuracy 0.78785\n",
            "Epoch 3: train set accuracy 0.81045\n",
            "Epoch 4: train set accuracy 0.8259\n",
            "Epoch 5: train set accuracy 0.8365333333333334\n",
            "Epoch 6: train set accuracy 0.8422166666666666\n",
            "Epoch 7: train set accuracy 0.8452\n",
            "Epoch 8: train set accuracy 0.8535333333333334\n",
            "Epoch 9: train set accuracy 0.8605\n",
            "Epoch 9: test set accuracy 0.8503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Larger layer size (13 * 13 * 5 output for layer 1, 6 * 6 * 10 output for layer 2)"
      ],
      "metadata": {
        "id": "sS9YL4NjNXDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comparison2_get_accuracy(model, dataloader):\n",
        "  count = 0\n",
        "  correct = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds = comparison2_network(images)\n",
        "      batch_correct = preds.argmax(dim = 1).eq(labels).sum().item()\n",
        "      batch_count = len(batch[0])\n",
        "      count += batch_count\n",
        "      correct += batch_correct\n",
        "  model.train()\n",
        "  return correct/count"
      ],
      "metadata": {
        "id": "zGoOKCXFNXDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Comparison2_Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 5, kernel_size = 3)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 5, out_channels = 10, kernel_size = 2)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 6 * 6 * 10, out_features = 100)\n",
        "    self.fc2 = nn.Linear(in_features = 100, out_features = 50)\n",
        "\n",
        "    self.out = nn.Linear(in_features = 50, out_features = 10)\n",
        "\n",
        "  # Define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # conv2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # fc1\n",
        "    # Use PyTorch's tensor operation t.reshape to flatten the tensor so it can \n",
        "    # be passed to the dense layer afterward\n",
        "    t = t.reshape(-1, 6 * 6 * 10)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # Don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "metadata": {
        "id": "S0VDqinyNXDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 1000\n",
        "shuffle = True\n",
        "epochs = 10\n",
        "\n",
        "comparison2_network = Comparison2_Network()\n",
        "comparison2_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "comparison2_optimizer = optim.Adam(comparison2_network.parameters(), lr = learning_rate)\n",
        "\n",
        "# Set the network to training mode\n",
        "comparison2_network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in comparison2_loader:\n",
        "    comparison2_images = batch[0]\n",
        "    comparison2_labels = batch[1]\n",
        "    comparison2_preds = comparison2_network(comparison2_images)\n",
        "    comparison2_loss = F.cross_entropy(comparison2_preds, comparison2_labels)\n",
        "\n",
        "    comparison2_optimizer.zero_grad()\n",
        "    comparison2_loss.backward()\n",
        "    comparison2_optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch, comparison2_get_accuracy(comparison2_network, comparison2_loader)))\n",
        "\n",
        "comparison2_test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch, comparison2_get_accuracy(comparison2_network, comparison2_test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0745f83-1b70-44f1-adf4-a22a04de60c4",
        "id": "zApksG_BNXDx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train set accuracy 0.6256666666666667\n",
            "Epoch 1: train set accuracy 0.7633333333333333\n",
            "Epoch 2: train set accuracy 0.78425\n",
            "Epoch 3: train set accuracy 0.7994333333333333\n",
            "Epoch 4: train set accuracy 0.8130666666666667\n",
            "Epoch 5: train set accuracy 0.82455\n",
            "Epoch 6: train set accuracy 0.8322666666666667\n",
            "Epoch 7: train set accuracy 0.84015\n",
            "Epoch 8: train set accuracy 0.8462166666666666\n",
            "Epoch 9: train set accuracy 0.8512166666666666\n",
            "Epoch 9: test set accuracy 0.841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More layers (3 convolutional layers)"
      ],
      "metadata": {
        "id": "5PgQgYq5X5tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comparison3_get_accuracy(model, dataloader):\n",
        "  count = 0\n",
        "  correct = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds = comparison3_network(images)\n",
        "      batch_correct = preds.argmax(dim = 1).eq(labels).sum().item()\n",
        "      batch_count = len(batch[0])\n",
        "      count += batch_count\n",
        "      correct += batch_correct\n",
        "  model.train()\n",
        "  return correct/count"
      ],
      "metadata": {
        "id": "rSb9KnzgX5t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network, expand on top of nn.Module\n",
        "class Comparison3_Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 5, kernel_size = 3)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 5, out_channels = 10, kernel_size = 3)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size = 3)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 2 * 2 * 20, out_features = 100)\n",
        "    self.fc2 = nn.Linear(in_features = 100, out_features = 50)\n",
        "\n",
        "    self.out = nn.Linear(in_features = 50, out_features = 10)\n",
        "\n",
        "  # Define forward function\n",
        "  def forward(self, t):\n",
        "    # conv1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # conv2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "\n",
        "    # conv3\n",
        "    t = self.conv3(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size = 2, stride = 1)\n",
        "\n",
        "    # fc1\n",
        "    # Use PyTorch's tensor operation t.reshape to flatten the tensor so it can \n",
        "    # be passed to the dense layer afterward\n",
        "    t = t.reshape(-1, 2 * 2 * 20)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # Don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "metadata": {
        "id": "iEAYia6MX5t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 800\n",
        "shuffle = True\n",
        "epochs = 10\n",
        "\n",
        "comparison3_network = Comparison3_Network()\n",
        "comparison3_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size)\n",
        "comparison3_optimizer = optim.Adam(comparison3_network.parameters(), lr = learning_rate)\n",
        "\n",
        "# Set the network to training mode\n",
        "comparison3_network.train()\n",
        "for epoch in range(epochs):\n",
        "  for batch in comparison3_loader:\n",
        "    comparison3_images = batch[0]\n",
        "    comparison3_labels = batch[1]\n",
        "    comparison3_preds = comparison3_network(comparison3_images)\n",
        "    comparison3_loss = F.cross_entropy(comparison3_preds, comparison3_labels)\n",
        "\n",
        "    comparison3_optimizer.zero_grad()\n",
        "    comparison3_loss.backward()\n",
        "    comparison3_optimizer.step()\n",
        "  print('Epoch {0}: train set accuracy {1}'.format(epoch, comparison3_get_accuracy(comparison3_network, comparison3_loader)))\n",
        "\n",
        "comparison3_test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size)\n",
        "print('Epoch {0}: test set accuracy {1}'.format(epoch, comparison3_get_accuracy(comparison3_network, comparison3_test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86626782-51e9-45ac-aa06-296598d56f7d",
        "id": "vWDOuamwX5t1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train set accuracy 0.5713\n",
            "Epoch 1: train set accuracy 0.6893333333333334\n",
            "Epoch 2: train set accuracy 0.7147166666666667\n",
            "Epoch 3: train set accuracy 0.7368\n",
            "Epoch 4: train set accuracy 0.74865\n",
            "Epoch 5: train set accuracy 0.7581833333333333\n",
            "Epoch 6: train set accuracy 0.7665\n",
            "Epoch 7: train set accuracy 0.7722166666666667\n",
            "Epoch 8: train set accuracy 0.77815\n",
            "Epoch 9: train set accuracy 0.7839666666666667\n",
            "Epoch 9: test set accuracy 0.7752\n"
          ]
        }
      ]
    }
  ]
}